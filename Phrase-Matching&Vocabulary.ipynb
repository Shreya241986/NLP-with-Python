{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Matching & Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER':'solarpower'}] #solarpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':'True'},{'LOWER':'power'}] #Solar_Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}] #Solar Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding all three patterns to matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The Solar Power industry continues to grow as solarpower increases. Solar-power is amazing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n"
     ]
    }
   ],
   "source": [
    " for match_id, start, end in found_matches:\n",
    "        string_id = nlp.vocab.strings[match_id] #SolarPower\n",
    "        span = doc[start:end]\n",
    "        print(match_id,string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to remove a particular pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making token rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER':'solarpower'}] # used for solarpower and SolarPower\n",
    "pattern2 =[{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}] # solar power, solar-power.\n",
    "#In between can be anything like solar_power, solar+power etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure you remove old solar power set\n",
    "matcher.add('SolarPower', None, pattern1, pattern2)\n",
    "doc2 = nlp(u\"Solar--power is solarpower Yay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reaganomics.txt', encoding = 'cp1252' ) as f: #encoding='utf8' was written\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodoo economics',\n",
    "               'supply-side economics', 'trickle-down economics', 'free-market economics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting each phrase to a document object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert list to spacy.tokens.doc.Doc",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-04edf2c9ddaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EconMatcher'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase_patterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.PhraseMatcher.add\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert list to spacy.tokens.doc.Doc"
     ]
    }
   ],
   "source": [
    "matcher.add('EconMatcher',None, phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '*' - essentially graps each document and passes indiviually into this matter as patterns\n",
    "matcher.add('EconMatcher',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3680293220734633682, 41, 45),\n",
       " (3680293220734633682, 49, 53),\n",
       " (3680293220734633682, 54, 56),\n",
       " (3680293220734633682, 61, 65),\n",
       " (3680293220734633682, 673, 677),\n",
       " (3680293220734633682, 2985, 2989)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 policies are commonly associated with supply-side economics, referred to as trickle\n",
      "3680293220734633682 EconMatcher 49 53 economics, referred to as trickle-down economics or voodoo economics by political\n",
      "3680293220734633682 EconMatcher 54 56 trickle-down economics or voodoo economics by political opponents, and\n",
      "3680293220734633682 EconMatcher 61 65 by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "\n",
      "3680293220734633682 EconMatcher 673 677 attracted a following from the supply-side economics movement, which formed in\n",
      "3680293220734633682 EconMatcher 2985 2989 became widely known as \"trickle-down economics\", due to the\n"
     ]
    }
   ],
   "source": [
    "#If you actually wanna grab the context of the document \n",
    "#where you can do is subtract a liitle bit from your start and add a little bit to your end.\n",
    "\n",
    "for matcher_id,start,end in found_matches:\n",
    "    string_id = nlp.vocab.strings[matcher_id]\n",
    "    span = doc3[start-5:end+5] #5 tokens back and 5 tokens forward\n",
    "    print(matcher_id, string_id,start,end,span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 5 tokens are there before supply-side economics and 5 tokens afterwards\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
